# Existing Projects Inventory

**Complete list of all betting/consensus-related projects discovered**

---

## 1. ConsensusProject
**Location**: `C:\Users\mpmmo\ConsensusProject\`
**Status**: Active, Production-ready
**Purpose**: Python-based consensus builder with comprehensive rules

### Files:
```
ConsensusProject/
â”œâ”€â”€ instructions/
â”‚   â””â”€â”€ MASTER_CONSENSUS_RULES.txt    # 200+ lines of rules
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ consensus_builder.py          # Main consensus engine
â”‚   â”œâ”€â”€ consensus_builder_v2.py       # Version 2
â”‚   â”œâ”€â”€ consensus_builder_final.py    # Final version
â”‚   â”œâ”€â”€ consensus_colab_version.py    # Google Colab version
â”‚   â”œâ”€â”€ data_fetcher.py               # Data fetching utility
â”‚   â””â”€â”€ fade_public_builder.py        # Fade the public logic
â”œâ”€â”€ input_files/                      # Put capper files here
â”œâ”€â”€ daily_output/                     # Results appear here
â”œâ”€â”€ notes/
â”‚   â””â”€â”€ PROJECT_OVERVIEW.md
â”œâ”€â”€ README.md
â”œâ”€â”€ RUN_CONSENSUS.bat                 # Quick runner
â””â”€â”€ QUICK_START.txt
```

### Key Features:
- Team name standardization (MLB, NBA, NFL, NHL, WNBA)
- Bet type parsing (ML, Spread, Totals, F5, Props)
- ðŸ”¥ Fire tags for 3+ capper consensus
- One vote per capper per unique bet
- Parlay leg counting
- Fade the public (70%+ threshold)

### Output Format:
1. TOP 5 OVERALL CONSENSUS
2. TOP 5 PARLAY COMBOS
3. TOP 3 PLAYER PROPS
4. TOP 3 BY SPORT
5. FADE THE PUBLIC

---

## 2. n8n-unified-sports-picks
**Location**: `C:\Users\mpmmo\n8n-unified-sports-picks\`
**Status**: Active, Ready to import
**Purpose**: n8n workflow for automated scraping to Google Sheets

### Files:
```
n8n-unified-sports-picks/
â”œâ”€â”€ IMPORT-ME-unified-sports-picks.json    # Main workflow
â”œâ”€â”€ READY-TO-IMPORT-WITH-COOKIES.json      # With authentication
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ n8n-unified-workflow-code.js       # HTML parser
â”‚   â”œâ”€â”€ n8n-today-filter-code.js           # Today's games only
â”‚   â”œâ”€â”€ n8n-dedupe-code.js                 # Deduplication
â”‚   â”œâ”€â”€ n8n-pagination-support.js          # Multi-page support
â”‚   â”œâ”€â”€ n8n-router-parser-code.js          # Route by site
â”‚   â”œâ”€â”€ n8n-COMPLETE-WORKING-PARSER.js     # Complete parser
â”‚   â”œâ”€â”€ n8n-FIXED-PARSER-V2.js
â”‚   â””â”€â”€ n8n-AUTO-DETECT-PARSER.js
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ SITE-LIST-CONFIGURATION.txt
â”‚   â”œâ”€â”€ SITE-PARSER-CONFIG.json
â”‚   â”œâ”€â”€ COMPLETE-SITE-LIST-COPY-PASTE.json
â”‚   â”œâ”€â”€ AUTHENTICATION-SETUP.md
â”‚   â”œâ”€â”€ DIMERS-COOKIE-STRING.txt
â”‚   â””â”€â”€ STEP-BY-STEP-ADD-COOKIES.md
â”œâ”€â”€ documentation/
â”‚   â”œâ”€â”€ QUICK-IMPORT-GUIDE.md
â”‚   â”œâ”€â”€ UNIFIED-SPORTS-PICKS-SETUP.md
â”‚   â”œâ”€â”€ N8N-LEARNING-GUIDE.md
â”‚   â”œâ”€â”€ README-N8N-UNIFIED-WORKFLOW.md
â”‚   â”œâ”€â”€ UNIFIED-WORKFLOW-SUMMARY.md
â”‚   â”œâ”€â”€ WORKFLOW-ANALYSIS-RECOMMENDATIONS.md
â”‚   â”œâ”€â”€ N8N-WORKFLOWS-SETUP-COMPLETE.md
â”‚   â””â”€â”€ N8N-WORKFLOW-BROWSER-GUIDE.md
â”œâ”€â”€ backups/
â”‚   â””â”€â”€ n8n-workflows-backup/
â”œâ”€â”€ PHASE-1-IMPLEMENTATION.md
â”œâ”€â”€ SOLUTION-FOR-DIFFICULT-SITES.md
â”œâ”€â”€ SOLUTION-COOKIE-AUTHENTICATION.md
â”œâ”€â”€ COMPLETE-IMPLEMENTATION-GUIDE.md
â”œâ”€â”€ AUTOMATED-SETUP-GUIDE.md
â””â”€â”€ README.md
```

### Workflow Output (Google Sheets):
| Column | Description |
|--------|-------------|
| Site | Source website |
| League | MLB, NFL, NBA, etc. |
| Date | Game date |
| Matchup | Team vs Team |
| Service | Capper name |
| Pick | The actual pick |
| RunDate | When scraped |

### Google Sheet ID:
`1dZe1s-yLHYvrLQEAlP0gGCVAFNbH433lV82iHzp-_BI`

### Sheet Tabs:
- BetFirm
- BoydsBets
- Dimers
- Covers
- SportsLine

---

## 3. capperbetsautomation
**Location**: `C:\Users\mpmmo\capperbetsautomation\`
**Status**: Planned, Detailed specification
**Purpose**: Full picks aggregator with API and dashboard

### Files:
```
capperbetsautomation/
â”œâ”€â”€ SPECIFICATION.md    # Detailed feature spec
â”œâ”€â”€ PLAN.md            # Implementation plan
â””â”€â”€ specs/
    â””â”€â”€ 001-picks-aggregator/
```

### Specification Highlights:

**Sources (7-8 total):**
- SportsLine
- BetFirm
- BoydsBets
- SportsCapping
- SportsMemo
- BallparkPal (requires 2FA)
- Reddit Sportsbook
- Action Network

**Architecture (Planned):**
```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/       # NormalizedPick, SourceStatus
â”‚   â”œâ”€â”€ scrapers/     # One per source
â”‚   â”œâ”€â”€ normalize/    # Teams, markets, dedupe
â”‚   â”œâ”€â”€ api/          # FastAPI endpoints
â”‚   â”œâ”€â”€ worker/       # Celery scheduling
â”‚   â””â”€â”€ notifications/ # Discord alerts
â””â”€â”€ tests/

web/
â”œâ”€â”€ templates/        # Jinja2
â”œâ”€â”€ static/
â””â”€â”€ app.py
```

**API Endpoints (Planned):**
```
GET  /api/v1/picks          # Get picks with filters
GET  /api/v1/sources        # Source health status
POST /api/v1/runs           # Trigger manual run
GET  /api/v1/runs/{id}      # Run status
POST /api/v1/sources/{name}/auth  # Submit 2FA
GET  /api/v1/stats          # Aggregated statistics
GET  /api/v1/export         # CSV/JSON export
```

**SLOs:**
- Total runtime < 3 minutes
- Success rate â‰¥ 95%
- Duplicate rate â‰¤ 2%
- Dashboard availability 99.9%

---

## 4. ConsensusAutomation
**Location**: `C:\Users\mpmmo\ConsensusAutomation\`
**Status**: In progress
**Purpose**: Python consensus with database and API

### Files:
```
ConsensusAutomation/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ pick.py
â”‚   â”‚   â””â”€â”€ run.py
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â””â”€â”€ base.py
â”‚   â”œâ”€â”€ normalization/
â”‚   â”‚   â”œâ”€â”€ teams.py
â”‚   â”‚   â””â”€â”€ markets.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â””â”€â”€ monitoring/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ canonical/
â”‚       â”œâ”€â”€ teams.json
â”‚       â””â”€â”€ markets.json
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_scrapers/
â”œâ”€â”€ alembic/                  # DB migrations
â”‚   â””â”€â”€ versions/
â”‚       â””â”€â”€ 001_initial_schema.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ seed_data.py
â”œâ”€â”€ CONSTITUTION.md
â”œâ”€â”€ SPECIFICATION.md
â”œâ”€â”€ ARCHITECTURE.md
â”œâ”€â”€ PROGRESS.md
â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md
â”œâ”€â”€ requirements-dev.txt
â”œâ”€â”€ alembic.ini
â””â”€â”€ .env.example
```

### Database Schema (SQLite â†’ PostgreSQL):
```sql
CREATE TABLE sources (id, name, url, config, last_success, failure_count)
CREATE TABLE picks (id, source_id, hash_key UNIQUE, sport, event, market)
CREATE TABLE runs (id, started_at, completed_at, sources_attempted)
CREATE TABLE team_aliases (canonical_name, alias, sport)
```

---

## 5. SportsBettingAutomation
**Location**: `C:\Users\mpmmo\SportsBettingAutomation\`
**Status**: Large collection, various states
**Purpose**: Scrapers, collectors, and automation scripts

### Major Subdirectories:

#### AutoCollector/freepicks/
```
apps/
â”œâ”€â”€ crawler/crawl.py
â”œâ”€â”€ parser/parse.py
â”œâ”€â”€ normalizer/normalize.py
â”œâ”€â”€ deduper/dedupe.py
â”œâ”€â”€ enricher/enrich.py
â”œâ”€â”€ exporter/export.py
â””â”€â”€ monitor/monitor.py
ops/
â”œâ”€â”€ run_all.py
â””â”€â”€ login_sportsline.py
```

#### ConsensusBuilder/
```
scripts/
â”œâ”€â”€ consensus_builder.py
â”œâ”€â”€ consensus_builder_v2.py
â”œâ”€â”€ consensus_builder_final.py
â”œâ”€â”€ consensus_colab_version.py
â”œâ”€â”€ data_fetcher.py
â””â”€â”€ fade_public_builder.py
```

#### AutomatedPickCollector/
```
automated_daily_picks.py
master_collector.py
enhanced_collector.py
exact_collector.py
fully_automated_collector.py
ballpark_pdf_collector.py
dimers_*.py (multiple versions)
sportsline_helper.py
daily_scheduler.py
```

#### Integration/
```
auto_pipeline.py
daily_scheduler.py
```

### Individual Scrapers:
| File | Purpose |
|------|---------|
| `AI_PICK_EXTRACTOR.py` | AI-powered pick extraction |
| `ALL_SPORTS_SMART_SCRAPER.py` | Multi-sport smart scraper |
| `GRAB_EVERYTHING_SCRAPER.py` | Comprehensive scraper |
| `EXACT_URL_SCRAPER.py` | URL-specific scraper |
| `DIMERS_TODAY_SCRAPER.py` | Dimers daily scraper |
| `BETFIRM_FULL_SCRAPER.py` | BetFirm complete scraper |
| `CTRL_A_SCRAPER.py` | Select-all text scraper |
| `scraper_dimers.py` | Dimers module |
| `scraper_betfirm.py` | BetFirm module |
| `scraper_covers.py` | Covers module |
| `brightdata_*.py` | BrightData proxy scrapers |
| `enhanced_scrapers.py` | Enhanced scraping logic |
| `production_scraper.py` | Production-ready scraper |

### Test Files:
- `test_public_sites.py`
- `test_public_sites_fixed.py`
- `test_individual_sites.py`
- `test_automation_system.py`
- `test_quick_scraper.py`
- `test_sportsline_login.py`

### Dashboard:
- `picks_dashboard.py`

---

## 6. Google Doc (Primary Data Source)
**Document ID**: `1QAUgTvFZq3PlA25vznkly8CHb4uNsIRYEZ0oXCitKxo`
**URL**: `https://docs.google.com/document/d/1QAUgTvFZq3PlA25vznkly8CHb4uNsIRYEZ0oXCitKxo/edit`
**Update Frequency**: Every 5 minutes
**Access**: Requires authentication

### Purpose:
- Primary source of daily picks
- Updated frequently throughout the day
- Contains picks from multiple cappers

---

## 7. Google Sheets (n8n Output)
**Sheet ID**: `1dZe1s-yLHYvrLQEAlP0gGCVAFNbH433lV82iHzp-_BI`

### Tabs:
- BetFirm
- BoydsBets
- Dimers
- Covers
- SportsLine

### Columns:
- Site
- League
- Date
- Matchup
- Service (Capper)
- Pick
- RunDate

---

## 8. n8n Cloud Instance
**URL**: `https://mslugga35.app.n8n.cloud`
**Purpose**: Workflow automation
**Workflows**: Unified Sports Picks Scraper

---

## 9. Consensus Files Location
**Path**: `C:\Users\mpmmo\OneDrive\Documents\consensusfiles`
**Purpose**: Input files for ConsensusProject
**Output**: Daily consensus files

---

## Summary Table

| Project | Language | Status | Primary Use |
|---------|----------|--------|-------------|
| ConsensusProject | Python | Production | Consensus building |
| n8n-unified-sports-picks | n8n/JS | Ready | Automated scraping |
| capperbetsautomation | Python | Planned | Full aggregator |
| ConsensusAutomation | Python | In progress | API + DB consensus |
| SportsBettingAutomation | Python | Various | Scrapers collection |
| Google Doc | - | Active | Primary data source |
| Google Sheets | - | Active | n8n output storage |
| n8n Cloud | - | Active | Workflow automation |

---

## Cappers Already Tracked

Based on existing systems, these cappers appear most frequently:

1. **BetFirm Cappers**:
   - Dave Price
   - Jack Jones
   - Pure Lock
   - Matt Fargo

2. **Covers Cappers**:
   - Chris Vasile
   - Quinn Allen
   - Neil Parker

3. **Other Sources**:
   - Dimers (AI picks)
   - SportsLine
   - Ballpark Pal
   - Consensus Leans
   - Lightning Bolt

---

## What Can Be Reused

### Directly Usable:
1. Team mappings from `consensus_builder.py`
2. n8n workflow JSON (`IMPORT-ME-unified-sports-picks.json`)
3. MASTER_CONSENSUS_RULES.txt
4. Google Sheets as data source
5. Canonical data (`teams.json`, `markets.json`)

### Needs Adaptation:
1. Python scrapers â†’ TypeScript for Next.js
2. Python consensus builder â†’ TypeScript for Next.js
3. Celery scheduling â†’ n8n/Vercel cron

### Already Integrated in New Website:
1. âœ… Team mappings (TypeScript port)
2. âœ… Consensus rules (TypeScript implementation)
3. âœ… Google Sheets fetching
4. âœ… API routes

---

*Last Updated: December 23, 2024*
